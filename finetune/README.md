# 🎯 Fine-tuning Directory

This directory contains fine-tuning scripts and configurations.

## 📁 Contents

- **Training Scripts**: LoRA fine-tuning implementations
- **Configurations**: Training parameters and settings
- **Models**: Fine-tuned model checkpoints

## 🚀 Current Status

- **Base Model**: LLaMA-2 7B
- **Fine-tuning Method**: LoRA (Low-Rank Adaptation)
- **Training Data**: Enhanced Bhagavad-Gītā dataset (381 examples)
- **Platform**: Google Colab Pro

## 📋 Next Steps

1. Upload enhanced dataset to Google Colab
2. Run LLaMA training notebook
3. Download trained model weights
4. Deploy to server
